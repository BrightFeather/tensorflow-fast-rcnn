{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This file contains a performance test of the ROI pooling layer. It runs both a forward and backward pass\n",
    "of the layer using a single batch of random data. The input size is set below and can be adjusted to taste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "home = os.getenv(\"HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since we've added custom operations, we need to import them. Tensorflow does not automatically add custom ops.\n",
    "# Adjust the paths below to your tensorflow source folder.\n",
    "\n",
    "# Import the forward op\n",
    "roi_pooling_module = tf.load_op_library(\n",
    "    home + \"/packages/tensorflow/bazel-bin/tensorflow/core/user_ops/roi_pooling_op.so\")\n",
    "roi_pooling_op = roi_pooling_module.roi_pooling\n",
    "\n",
    "# Import the gradient op\n",
    "roi_pooling_module_grad = tf.load_op_library(\n",
    "    home + \"/packages/tensorflow/bazel-bin/tensorflow/core/user_ops/roi_pooling_op_grad.so\")\n",
    "roi_pooling_op_grad = roi_pooling_module_grad.roi_pooling_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configuring the size of the benchmark inputs.\n",
    "# This is about as large as my card (2GB memory) can handle\n",
    "num_batches = 150\n",
    "num_channels = 10\n",
    "image_height = 200\n",
    "image_width = 200\n",
    "result_size = 20\n",
    "\n",
    "input_shape = (num_batches, num_channels, image_height, image_width)\n",
    "other_shape = (num_batches, num_channels, 1, result_size, result_size)\n",
    "result_shape = (result_size, result_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A ROI. Just use the whole image\n",
    "rois = [[0, 0, image_height, image_width]]\n",
    "rois = [rois for x in range(num_batches)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We pre-compute the argmax so we can benchmark the gradient function separately\n",
    "def get_argmax():\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    data = tf.constant(np.random.random(input_shape).astype(np.float32))\n",
    "    grad = tf.constant(np.random.random((num_batches, num_channels, 1, result_shape[0], result_shape[1])).astype(np.float32))\n",
    "    rois_tensor = tf.constant(np.asarray(rois).astype(np.int32))\n",
    "    output_shape_tensor = tf.constant(np.asarray(result_shape).astype(np.int32))\n",
    "    input_shape_tensor = array_ops.shape(data)\n",
    "\n",
    "    result, argmax = roi_pooling_op(data, rois_tensor, output_shape_tensor)\n",
    "\n",
    "    return sess.run(argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "argmax_data = get_argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the random inputs ready\n",
    "thing1 = np.random.random(input_shape).astype(np.float32)\n",
    "thing2 = np.random.random((num_batches, num_channels, 1, result_shape[0], result_shape[1])).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The main benchmarking function. Device is \"gpu\" or \"cpu\".\n",
    "def benchmark(device):\n",
    "    sess = tf.Session()\n",
    "    with tf.device(\"/{}:0\".format(device)):\n",
    "        \n",
    "        # Set up the inputs\n",
    "        data = tf.constant(thing1)\n",
    "        grad = tf.constant(thing2)\n",
    "        argmax_precomp = tf.constant(argmax_data)\n",
    "\n",
    "        # We make them into variables so they can be cached to isolate load time from op time\n",
    "        data_var = tf.Variable(data, dtype=tf.float32, name=\"var1\")\n",
    "        grad_var = tf.Variable(grad, dtype=tf.float32, name=\"var2\")\n",
    "        \n",
    "        # Other small inputs\n",
    "        rois_tensor = tf.constant(np.asarray(rois).astype(np.int32))\n",
    "        output_shape_tensor = tf.constant(np.asarray(result_shape).astype(np.int32))\n",
    "        input_shape_tensor = array_ops.shape(data)\n",
    "    \n",
    "        # The actual ops\n",
    "        result, argmax = roi_pooling_op(data_var, rois_tensor, output_shape_tensor)\n",
    "        \n",
    "        # We call the gradient op explicitly to avoid the lookup overhead\n",
    "        gradient_explicit = roi_pooling_op_grad(grad_var, argmax_precomp, input_shape_tensor)\n",
    "\n",
    "        # Initialize the variables\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess.run([init])\n",
    "    \n",
    "        # Run timings for the forward pass\n",
    "        start = time.time()\n",
    "        result_out, argmax_out = sess.run([result, argmax])\n",
    "        print(\"Forward Pass took {} seconds\".format(time.time() - start))\n",
    "        \n",
    "        # Since we can't cache argmax (because it's int32, long story..)\n",
    "        # we compute how long it takes to load, and subtract that from the total time\n",
    "        overhead = time.time()\n",
    "        sess.run([argmax_precomp, grad_var, input_shape_tensor])\n",
    "        overhead = time.time() - start\n",
    "        \n",
    "        # Timings for backward pass\n",
    "        start = time.time()\n",
    "        sess.run([gradient_explicit])\n",
    "        print(\"Backwards Pass took {} seconds\".format(time.time() - start - overhead))\n",
    "\n",
    "    sess.close()  \n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass took 0.08390259742736816 seconds\n",
      "Backwards Pass took 0.175032377243042 seconds\n"
     ]
    }
   ],
   "source": [
    "# Benchmark the CPU\n",
    "benchmark(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Pass took 0.06426715850830078 seconds\n",
      "Backwards Pass took 0.08208394050598145 seconds\n"
     ]
    }
   ],
   "source": [
    "# Benchmark the gpu\n",
    "benchmark(\"gpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
